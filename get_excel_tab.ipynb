{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import argparse\n",
    "\n",
    "import imageio\n",
    "import numpy as np\n",
    "import torch \n",
    "import scipy.signal\n",
    "from tqdm import trange\n",
    "import os\n",
    "import json\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "mse2psnr = lambda x : -10. * torch.log(x) / torch.log(torch.Tensor([10.]).to(device))\n",
    "\n",
    "def rgb_ssim(img0, img1, max_val,\n",
    "             filter_size=11,\n",
    "             filter_sigma=1.5,\n",
    "             k1=0.01,\n",
    "             k2=0.03,\n",
    "             return_map=False):\n",
    "    # Modified from https://github.com/google/mipnerf/blob/16e73dfdb52044dcceb47cda5243a686391a6e0f/internal/math.py#L58\n",
    "    assert len(img0.shape) == 3\n",
    "    assert img0.shape[-1] == 3\n",
    "    assert img0.shape == img1.shape\n",
    "\n",
    "    # Construct a 1D Gaussian blur filter.\n",
    "    hw = filter_size // 2\n",
    "    shift = (2 * hw - filter_size + 1) / 2\n",
    "    f_i = ((np.arange(filter_size) - hw + shift) / filter_sigma)**2\n",
    "    filt = np.exp(-0.5 * f_i)\n",
    "    filt /= np.sum(filt)\n",
    "\n",
    "    # Blur in x and y (faster than the 2D convolution).\n",
    "    def convolve2d(z, f):\n",
    "        return scipy.signal.convolve2d(z, f, mode='valid')\n",
    "\n",
    "    filt_fn = lambda z: np.stack([\n",
    "        convolve2d(convolve2d(z[...,i], filt[:, None]), filt[None, :])\n",
    "        for i in range(z.shape[-1])], -1)\n",
    "    mu0 = filt_fn(img0)\n",
    "    mu1 = filt_fn(img1)\n",
    "    mu00 = mu0 * mu0\n",
    "    mu11 = mu1 * mu1\n",
    "    mu01 = mu0 * mu1\n",
    "    sigma00 = filt_fn(img0**2) - mu00\n",
    "    sigma11 = filt_fn(img1**2) - mu11\n",
    "    sigma01 = filt_fn(img0 * img1) - mu01\n",
    "\n",
    "    # Clip the variances and covariances to valid values.\n",
    "    # Variance must be non-negative:\n",
    "    sigma00 = np.maximum(0., sigma00)\n",
    "    sigma11 = np.maximum(0., sigma11)\n",
    "    sigma01 = np.sign(sigma01) * np.minimum(\n",
    "        np.sqrt(sigma00 * sigma11), np.abs(sigma01))\n",
    "    c1 = (k1 * max_val)**2\n",
    "    c2 = (k2 * max_val)**2\n",
    "    numer = (2 * mu01 + c1) * (2 * sigma01 + c2)\n",
    "    denom = (mu00 + mu11 + c1) * (sigma00 + sigma11 + c2)\n",
    "    ssim_map = numer / denom\n",
    "    ssim = np.mean(ssim_map)\n",
    "    return ssim_map if return_map else ssim\n",
    "\n",
    "__LPIPS__ = {}\n",
    "def init_lpips(net_name, device):\n",
    "    assert net_name in ['alex', 'vgg']\n",
    "    import lpips\n",
    "    print(f'init_lpips: lpips_{net_name}')\n",
    "    return lpips.LPIPS(net=net_name, version='0.1').eval()\n",
    "\n",
    "def rgb_lpips(np_gt, np_im, net_name, device):\n",
    "    if net_name not in __LPIPS__:\n",
    "        __LPIPS__[net_name] = init_lpips(net_name, device)\n",
    "    gt = torch.from_numpy(np_gt).permute([2, 0, 1]).contiguous()\n",
    "    im = torch.from_numpy(np_im).permute([2, 0, 1]).contiguous()\n",
    "    return __LPIPS__[net_name](gt, im, normalize=True).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3732327/3338674085.py:16: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  torch_ref_imgs = torch.stack([torch.from_numpy(imageio.imread(name))/255. for name in ref_png_filenames]) #(N_img, H, W, 3)\n",
      "/tmp/ipykernel_3732327/3338674085.py:32: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  torch_render_imgs = torch.stack([torch.from_numpy(imageio.imread(name))/255. for name in render_png_filenames]) #(N_img, H, W, 3)\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_lpips: lpips_alex\n",
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n",
      "Loading model from: /work/Users/lisicheng/Environment/anaconda3/envs/steernerf/lib/python3.8/site-packages/lpips/weights/v0.1/alex.pth\n",
      "init_lpips: lpips_vgg\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: /work/Users/lisicheng/Environment/anaconda3/envs/steernerf/lib/python3.8/site-packages/lpips/weights/v0.1/vgg.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.31s/it]\n",
      "100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n",
      "100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n",
      "100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n",
      "100%|██████████| 4/4 [00:07<00:00,  1.78s/it]\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    start_index = 700\n",
    "    num_images = 5\n",
    "\n",
    "config = CFG()\n",
    "\n",
    "config.start_index = 700\n",
    "config.num_images = 5\n",
    "\n",
    "# glob to get all ref. png files\n",
    "ref_png_filenames = []\n",
    "all_ref_png_filenames = sorted(glob.glob(f\"./kitti360_{config.start_index}_{config.num_images}/*.png\"))\n",
    "for idx, filename in enumerate(all_ref_png_filenames):\n",
    "    if idx % 4 == 2 or idx % 4 == 3:\n",
    "        ref_png_filenames.append(filename)\n",
    "torch_ref_imgs = torch.stack([torch.from_numpy(imageio.imread(name))/255. for name in ref_png_filenames]) #(N_img, H, W, 3)\n",
    "\n",
    "\n",
    "metrics_dict = {}\n",
    "\n",
    "PSNRs_across_QP = []\n",
    "SSIMs_across_QP = []\n",
    "LPIPS_Alexs_across_QP = []\n",
    "LPIPS_VGGs_across_QP = []\n",
    "\n",
    "bitrate_across_QP = []\n",
    "\n",
    "for QP in [\"RP0\", \"QP1\", \"QP2\", \"QP3\", \"QP4\"]:\n",
    "# for QP in [\"RP0\"]:\n",
    "# glob to get all YUV files\n",
    "    render_png_filenames = sorted(glob.glob(f\"./kitti360_{config.start_index}_{config.num_images}/tmiv_enc/{QP}/render/*.png\"))\n",
    "    torch_render_imgs = torch.stack([torch.from_numpy(imageio.imread(name))/255. for name in render_png_filenames]) #(N_img, H, W, 3)\n",
    "\n",
    "    PSNRs = []\n",
    "    SSIMs = []\n",
    "    LPIPS_Alexs = []\n",
    "    LPIPS_VGGs = []\n",
    "    \n",
    "    for i in trange(torch_ref_imgs.shape[0]):\n",
    "        mse = torch.mean((torch_render_imgs[i] - torch_ref_imgs[i]) ** 2)\n",
    "        psnr = mse2psnr(mse) # return torch.Tensor.cuda()\n",
    "\n",
    "        ssim = rgb_ssim(torch_render_imgs[i], torch_ref_imgs[i], 1) # return nd.array\n",
    "        l_a = rgb_lpips(torch_render_imgs[i].numpy(), torch_ref_imgs[i].numpy(), 'alex', device)\n",
    "        l_v = rgb_lpips(torch_render_imgs[i].numpy(), torch_ref_imgs[i].numpy(), 'vgg', device) # return float\n",
    "\n",
    "        PSNRs.append(psnr.cpu().numpy())\n",
    "        SSIMs.append(ssim)\n",
    "        LPIPS_Alexs.append(l_a)\n",
    "        LPIPS_VGGs.append(l_v)\n",
    "\n",
    "    PSNRs_across_QP.append(PSNRs)\n",
    "    SSIMs_across_QP.append(SSIMs)\n",
    "    LPIPS_Alexs_across_QP.append(LPIPS_Alexs)\n",
    "    LPIPS_VGGs_across_QP.append(LPIPS_VGGs)\n",
    "\n",
    "\n",
    "\n",
    "    # info_dict = {\n",
    "    #     \"PSNR\": torch.stack(PSNRs).mean().item(),\n",
    "    #     \"SSIM\": sum(SSIMs)/len(SSIMs),\n",
    "    #     \"LPIPS_A\": sum(LPIPS_Alexs)/len(LPIPS_Alexs),\n",
    "    #     \"LPIPS_V\": sum(LPIPS_VGGs)/len(LPIPS_VGGs)\n",
    "    # }\n",
    "    # import pdb; pdb.set_trace()\n",
    "\n",
    "    # import pdb; pdb.set_trace()\n",
    "    bitstream_filenames = sorted(glob.glob(f\"./kitti360_{config.start_index}_{config.num_images}/tmiv_enc/{QP}/*.bit\"))\n",
    "    bitstream_size = sum([os.path.getsize(file_name) for file_name in bitstream_filenames])\n",
    "    bitrate = bitstream_size/1e3*240 # Kbps float\n",
    "\n",
    "    bitrate_across_QP.append(bitrate) \n",
    "\n",
    "    # info_dict.update(\n",
    "    #     {\"file_size\": bitstream_size,\n",
    "    #      \"bitrate\": bitrate}\n",
    "    # )\n",
    "\n",
    "    # print(QP, f\"{bitstream_size/1e6} MB\", f\"{bitstream_size/1e6*240} Mbps\")\n",
    "    # metrics_dict.update({\n",
    "    #     QP: info_dict\n",
    "    # })\n",
    "\n",
    "os.makedirs(f\"./kitti360_{config.start_index}_{config.num_images}/rd\", exist_ok=True)\n",
    "\n",
    "with open(f\"./kitti360_{config.start_index}_{config.num_images}/rd/rd.json\", \"w\") as file:\n",
    "    json.dump(metrics_dict, file)\n",
    "\n",
    "# bitrate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_PSNR_array = np.asarray(PSNRs_across_QP)[:,:,0].transpose().flatten()\n",
    "all_SSIM_array = np.asarray(SSIMs_across_QP).transpose().flatten()\n",
    "all_LPIPS_Alex_array = np.asarray(LPIPS_Alexs_across_QP).transpose().flatten()\n",
    "all_LPIPS_VGG_array = np.asarray(LPIPS_VGGs_across_QP).transpose().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_results = np.column_stack((all_PSNR_array, all_SSIM_array, all_LPIPS_Alex_array, all_LPIPS_VGG_array))\n",
    "np.savetxt(f\"./kitti360_{config.start_index}_{config.num_images}/rd/qulaity_metric.csv\", concat_results, delimiter=',', fmt='%.4f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitrate_results = np.asarray(bitrate_across_QP[1:]).reshape([-1, 1])\n",
    "np.savetxt(f\"./kitti360_{config.start_index}_{config.num_images}/rd/bitrate.csv\", bitrate_results, delimiter=',', fmt='%.2f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
